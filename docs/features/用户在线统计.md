# 用户在线统计功能设计

基于 Linus 式架构分析，设计聊天室用户在线统计功能，包含实时统计和历史报表。

## 核心判断

✅ **值得做**：在线统计是用户体验基本需求，管理员报表是运营决策基础

## 关键洞察

- **数据结构**：双层架构 - Redis Sets实时状态 + PostgreSQL时序数据历史分析
- **复杂度**：实时统计简单，历史报表需要事件采集和聚合机制
- **风险点**：时序数据存储爆炸，需要分层存储和生命周期管理

## 设计缺陷修正

**原始设计问题**：只考虑实时状态，忽略管理员历史趋势分析需求

**修正后架构**：

- **实时层**：Redis Sets + WebSocket推送（用户体验）
- **历史层**：PostgreSQL时序表 + 聚合任务（管理员报表）
- **数据流**：事件采集 → 异步写入 → 定时聚合 → 报表查询

---

## 1. 修改点

### 实时统计层（保持现有设计）

- **PresenceManager trait扩展** - 添加统计相关方法
- **Redis统计查询优化** - 实现高效计数查询
- **WebSocket消息类型扩展** - 新增在线统计推送
- **REST API端点** - 提供实时统计数据查询接口
- **内存缓存层** - 避免频繁Redis查询

### 历史报表层（新增设计）

- **时序数据采集层** - 记录每个用户状态变化事件
- **PostgreSQL时序表** - 存储历史统计数据
- **数据聚合任务** - 定时生成报表数据（小时/日/月/年）
- **管理员报表API** - 支持多维度查询
- **数据生命周期管理** - 自动清理过期数据
- **异步事件队列** - 批量写入，不阻塞实时功能

## 2. 修改逻辑与机理

### 双层数据架构

```rust
// 实时统计接口（扩展现有PresenceManager）
#[async_trait]
pub trait PresenceManager: Send + Sync {
    // 现有方法保持不变...

    // 实时统计方法
    async fn get_online_count(&self, room_id: RoomId) -> Result<u64, ApplicationError>;
    async fn get_online_stats(&self, room_id: RoomId) -> Result<OnlineStats, ApplicationError>;

    // 历史数据采集方法
    async fn record_presence_event(&self, event: UserPresenceEvent) -> Result<(), ApplicationError>;
    async fn get_stats_report(&self, query: StatsReportQuery) -> Result<Vec<OnlineStatsAggregated>, ApplicationError>;
}

// 实时统计数据结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OnlineStats {
    pub room_id: RoomId,
    pub online_count: u64,
    pub timestamp: DateTime<Utc>,
}

// 历史事件数据结构
#[derive(Debug, Clone)]
pub struct UserPresenceEvent {
    pub event_id: Uuid,
    pub user_id: UserId,
    pub room_id: RoomId,
    pub event_type: PresenceEventType,
    pub timestamp: DateTime<Utc>,
    pub session_id: Uuid,  // 用于计算在线时长
    pub user_ip: Option<String>,
    pub user_agent: Option<String>,
}

#[derive(Debug, Clone)]
pub enum PresenceEventType {
    Connected,
    Disconnected,
    Heartbeat,  // 用于检测僵尸连接
}

// 聚合统计数据（报表用）
#[derive(Debug, Clone)]
pub struct OnlineStatsAggregated {
    pub room_id: RoomId,
    pub time_bucket: DateTime<Utc>,  // 时间桶（小时/日/月）
    pub granularity: TimeGranularity,
    pub peak_online_count: u64,      // 峰值在线人数
    pub avg_online_count: f64,       // 平均在线人数
    pub total_connections: u64,      // 总连接数
    pub unique_users: u64,           // 去重用户数
    pub avg_session_duration: f64,   // 平均会话时长（秒）
}

#[derive(Debug, Clone)]
pub enum TimeGranularity {
    Hour,
    Day,
    Week,
    Month,
    Year,
}

// 管理员报表查询参数
#[derive(Debug, Clone)]
pub struct StatsReportQuery {
    pub room_ids: Option<Vec<RoomId>>,  // 可选房间过滤
    pub start_time: DateTime<Utc>,
    pub end_time: DateTime<Utc>,
    pub granularity: TimeGranularity,
    pub metrics: Vec<StatsMetric>,
}

#[derive(Debug, Clone)]
pub enum StatsMetric {
    OnlineCount,
    UniqueUsers,
    SessionDuration,
    ConnectionFrequency,
    PeakHours,
}
```

### 异步事件采集系统

```rust
// 异步事件采集器（不阻塞实时功能）
pub struct PresenceEventCollector {
    event_queue: Arc<RwLock<VecDeque<UserPresenceEvent>>>,
    db_pool: Arc<sqlx::PgPool>,
    flush_interval: Duration,
}

impl PresenceEventCollector {
    // 批量异步写入，不阻塞实时功能
    async fn flush_events(&self) -> Result<(), ApplicationError> {
        let mut queue = self.event_queue.write().await;
        if queue.is_empty() {
            return Ok(());
        }

        let events: Vec<_> = queue.drain(..).collect();
        drop(queue);

        // 批量插入PostgreSQL时序表
        let mut tx = self.db_pool.begin().await?;

        for chunk in events.chunks(1000) {  // 批量插入提高性能
            sqlx::query!(
                r#"
                INSERT INTO presence_events (
                    event_id, user_id, room_id, event_type,
                    timestamp, session_id, user_ip
                ) SELECT * FROM UNNEST($1::uuid[], $2::uuid[], $3::uuid[],
                                      $4::text[], $5::timestamptz[], $6::uuid[], $7::text[])
                "#,
                &chunk.iter().map(|e| e.event_id).collect::<Vec<_>>(),
                &chunk.iter().map(|e| e.user_id.into()).collect::<Vec<_>>(),
                &chunk.iter().map(|e| e.room_id.into()).collect::<Vec<_>>(),
                &chunk.iter().map(|e| e.event_type.to_string()).collect::<Vec<_>>(),
                &chunk.iter().map(|e| e.timestamp).collect::<Vec<_>>(),
                &chunk.iter().map(|e| e.session_id).collect::<Vec<_>>(),
                &chunk.iter().map(|e| e.user_ip.as_deref().unwrap_or("unknown")).collect::<Vec<_>>(),
            ).execute(&mut *tx).await?;
        }

        tx.commit().await?;
        Ok(())
    }
}

// 用户连接时同时处理实时和历史数据
impl RedisPresenceManager {
    async fn user_connected_with_full_tracking(
        &self,
        room_id: RoomId,
        user_id: UserId,
        session_id: Uuid,
        broadcaster: &dyn MessageBroadcaster,
        collector: &PresenceEventCollector
    ) -> Result<(), ApplicationError> {
        // 1. 原有实时逻辑
        self.user_connected(room_id, user_id).await?;

        // 2. 记录历史事件（异步，不阻塞）
        let event = UserPresenceEvent {
            event_id: Uuid::new_v4(),
            user_id,
            room_id,
            event_type: PresenceEventType::Connected,
            timestamp: Utc::now(),
            session_id,
            user_ip: None, // 从请求上下文获取
            user_agent: None,
        };
        collector.record_event(event).await?;

        // 3. 清除实时缓存
        self.invalidate_cache(room_id).await;

        // 4. 广播实时统计更新
        let stats = self.get_online_stats(room_id).await?;
        let message = WebSocketMessage::OnlineStatsUpdate(stats);
        broadcaster.broadcast(MessageBroadcast::stats(room_id, message)).await?;

        Ok(())
    }
}
```

### 数据聚合任务

```rust
// 定时聚合任务
pub struct StatsAggregator {
    db_pool: Arc<sqlx::PgPool>,
}

impl StatsAggregator {
    // 每小时运行，聚合上一小时的数据
    pub async fn aggregate_hourly_stats(&self) -> Result<(), ApplicationError> {
        let hour_ago = Utc::now() - Duration::hours(1);
        let hour_start = hour_ago.with_minute(0).unwrap().with_second(0).unwrap();
        let hour_end = hour_start + Duration::hours(1);

        // 复杂的SQL聚合查询
        let stats = sqlx::query_as!(
            OnlineStatsAggregated,
            r#"
            WITH session_stats AS (
                -- 计算每个会话的持续时间
                SELECT
                    room_id,
                    session_id,
                    MIN(timestamp) as session_start,
                    MAX(timestamp) as session_end,
                    EXTRACT(EPOCH FROM (MAX(timestamp) - MIN(timestamp))) as session_duration
                FROM presence_events
                WHERE timestamp >= $1 AND timestamp < $2
                GROUP BY room_id, session_id
            ),
            hourly_peaks AS (
                -- 计算每5分钟间隔的在线人数峰值
                SELECT
                    room_id,
                    DATE_TRUNC('minute', timestamp - INTERVAL '0 minutes' % INTERVAL '5 minutes') as time_slot,
                    COUNT(DISTINCT user_id) as online_count
                FROM presence_events e1
                WHERE timestamp >= $1 AND timestamp < $2
                  AND event_type = 'Connected'
                  AND NOT EXISTS (
                      SELECT 1 FROM presence_events e2
                      WHERE e2.user_id = e1.user_id
                        AND e2.room_id = e1.room_id
                        AND e2.event_type = 'Disconnected'
                        AND e2.timestamp > e1.timestamp
                        AND e2.timestamp <= time_slot + INTERVAL '5 minutes'
                  )
                GROUP BY room_id, time_slot
            )
            SELECT
                s.room_id,
                $1 as time_bucket,
                'Hour' as granularity,
                COALESCE(MAX(p.online_count), 0) as peak_online_count,
                COALESCE(AVG(p.online_count), 0) as avg_online_count,
                COUNT(DISTINCT s.session_id) as total_connections,
                COUNT(DISTINCT e.user_id) as unique_users,
                COALESCE(AVG(s.session_duration), 0) as avg_session_duration
            FROM session_stats s
            LEFT JOIN hourly_peaks p ON s.room_id = p.room_id
            LEFT JOIN presence_events e ON s.room_id = e.room_id
                AND e.timestamp >= $1 AND e.timestamp < $2
            GROUP BY s.room_id
            "#,
            hour_start,
            hour_end
        )
        .fetch_all(&*self.db_pool)
        .await?;

        // 插入聚合结果
        for stat in stats {
            sqlx::query!(
                r#"
                INSERT INTO stats_aggregated (
                    room_id, time_bucket, granularity, peak_online_count,
                    avg_online_count, total_connections, unique_users, avg_session_duration
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                ON CONFLICT (room_id, time_bucket, granularity)
                DO UPDATE SET
                    peak_online_count = EXCLUDED.peak_online_count,
                    avg_online_count = EXCLUDED.avg_online_count,
                    total_connections = EXCLUDED.total_connections,
                    unique_users = EXCLUDED.unique_users,
                    avg_session_duration = EXCLUDED.avg_session_duration
                "#,
                stat.room_id,
                stat.time_bucket,
                stat.granularity.to_string(),
                stat.peak_online_count as i64,
                stat.avg_online_count,
                stat.total_connections as i64,
                stat.unique_users as i64,
                stat.avg_session_duration
            )
            .execute(&*self.db_pool)
            .await?;
        }

        Ok(())
    }
}
```

### 管理员报表API

```rust
// GET /admin/api/stats/reports
pub async fn get_stats_report(
    Query(query): Query<StatsReportQuery>,
    State(app_state): State<AppState>,
    admin: AdminUser,  // 权限验证
) -> Result<Json<StatsReportResponse>, ApiError> {

    // 记录管理员查询审计日志
    audit_log::record_admin_action(
        admin.user_id,
        "stats_query",
        serde_json::to_value(&query)?
    ).await?;

    let start = Instant::now();
    let stats = app_state
        .presence_manager
        .get_stats_report(query)
        .await?;

    let response = StatsReportResponse {
        stats,
        generated_at: Utc::now(),
        query_duration: start.elapsed(),
    };

    Ok(Json(response))
}

#[derive(Debug, Serialize)]
pub struct StatsReportResponse {
    pub stats: Vec<OnlineStatsAggregated>,
    pub generated_at: DateTime<Utc>,
    pub query_duration: Duration,
}
```

### 数据库表结构

```sql
-- 原始事件表（分区表，按时间分区）
CREATE TABLE presence_events (
    event_id UUID PRIMARY KEY,
    user_id UUID NOT NULL,
    room_id UUID NOT NULL,
    event_type TEXT NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL,
    session_id UUID NOT NULL,
    user_ip TEXT,
    user_agent TEXT
) PARTITION BY RANGE (timestamp);

-- 创建月度分区（自动化脚本定期创建）
CREATE TABLE presence_events_2024_01 PARTITION OF presence_events
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- 聚合统计表
CREATE TABLE stats_aggregated (
    room_id UUID NOT NULL,
    time_bucket TIMESTAMPTZ NOT NULL,
    granularity TEXT NOT NULL,
    peak_online_count BIGINT NOT NULL,
    avg_online_count DOUBLE PRECISION NOT NULL,
    total_connections BIGINT NOT NULL,
    unique_users BIGINT NOT NULL,
    avg_session_duration DOUBLE PRECISION NOT NULL,
    PRIMARY KEY (room_id, time_bucket, granularity)
);

-- 索引优化
CREATE INDEX idx_presence_events_room_time ON presence_events (room_id, timestamp);
CREATE INDEX idx_presence_events_user_session ON presence_events (user_id, session_id);
CREATE INDEX idx_stats_aggregated_time_gran ON stats_aggregated (time_bucket, granularity);

-- 数据生命周期管理
-- 原始事件保留30天
-- 聚合数据按粒度保留不同时间：小时数据6个月，日数据2年，月数据永久
```

## 3. 测试用例

### 基础功能测试

```rust
#[tokio::test]
async fn test_online_count_accuracy() {
    let presence = setup_redis_presence().await;
    let room_id = RoomId::new();

    // 初始状态
    assert_eq!(presence.get_online_count(room_id).await.unwrap(), 0);

    // 添加用户
    let users = create_test_users(5).await;
    for user in &users {
        presence.user_connected(room_id, *user).await.unwrap();
    }

    assert_eq!(presence.get_online_count(room_id).await.unwrap(), 5);

    // 移除用户
    presence.user_disconnected(room_id, users[0]).await.unwrap();
    assert_eq!(presence.get_online_count(room_id).await.unwrap(), 4);
}
```

### 缓存机制测试

```rust
#[tokio::test]
async fn test_stats_caching() {
    let presence = setup_redis_presence().await;
    let room_id = RoomId::new();

    // 第一次查询
    let start = Instant::now();
    let count1 = presence.get_online_count(room_id).await.unwrap();
    let first_duration = start.elapsed();

    // 第二次查询（应该命中缓存）
    let start = Instant::now();
    let count2 = presence.get_online_count(room_id).await.unwrap();
    let second_duration = start.elapsed();

    assert_eq!(count1, count2);
    assert!(second_duration < first_duration / 2); // 缓存应该更快
}
```

### WebSocket广播测试

```rust
#[tokio::test]
async fn test_stats_broadcast_on_user_change() {
    let presence = setup_redis_presence().await;
    let broadcaster = setup_test_broadcaster().await;
    let room_id = RoomId::new();
    let user_id = UserId::new();

    let mut stream = broadcaster.subscribe(room_id).await.unwrap();

    // 用户连接应该触发统计广播
    presence.user_connected_with_broadcast(room_id, user_id, &broadcaster).await.unwrap();

    let message = stream.recv().await.unwrap();
    match message.message {
        WebSocketMessage::OnlineStatsUpdate(stats) => {
            assert_eq!(stats.room_id, room_id);
            assert_eq!(stats.online_count, 1);
        }
        _ => panic!("Expected OnlineStatsUpdate message"),
    }
}
```

### API端点测试

```rust
#[tokio::test]
async fn test_api_endpoint() {
    let app = setup_test_app().await;
    let room = create_test_room().await;

    // 添加一些在线用户
    simulate_users_online(room.id, 3).await;

    let response = app
        .get(&format!("/api/rooms/{}/stats", room.id))
        .send()
        .await
        .unwrap();

    assert_eq!(response.status(), 200);

    let stats: OnlineStats = response.json().await.unwrap();
    assert_eq!(stats.room_id, room.id);
    assert_eq!(stats.online_count, 3);
}
```

### 历史数据采集测试

```rust
#[tokio::test]
async fn test_event_collection() {
    let collector = setup_event_collector().await;
    let room_id = RoomId::new();
    let user_id = UserId::new();
    let session_id = Uuid::new_v4();

    // 记录用户上线事件
    let event = UserPresenceEvent {
        event_id: Uuid::new_v4(),
        user_id,
        room_id,
        event_type: PresenceEventType::Connected,
        timestamp: Utc::now(),
        session_id,
        user_ip: Some("127.0.0.1".to_string()),
        user_agent: None,
    };

    collector.record_event(event).await.unwrap();

    // 等待异步写入
    tokio::time::sleep(Duration::from_secs(1)).await;

    // 验证数据已持久化
    let events = query_events_from_db(room_id, user_id).await.unwrap();
    assert_eq!(events.len(), 1);
    assert_eq!(events[0].event_type, PresenceEventType::Connected);
}
```

### 数据聚合测试

```rust
#[tokio::test]
async fn test_hourly_aggregation() {
    let aggregator = setup_aggregator().await;
    let room_id = RoomId::new();

    // 模拟一小时内的用户活动
    simulate_user_activity(room_id, 10, Duration::hours(1)).await;

    // 运行聚合任务
    aggregator.aggregate_hourly_stats().await.unwrap();

    // 验证聚合结果
    let stats = query_aggregated_stats(room_id, TimeGranularity::Hour).await.unwrap();
    assert!(stats.peak_online_count > 0);
    assert!(stats.avg_online_count > 0.0);
    assert_eq!(stats.unique_users, 10);
}
```

### 管理员报表API测试

```rust
#[tokio::test]
async fn test_admin_stats_report() {
    let app = setup_admin_app().await;
    let admin = create_admin_user().await;
    let room = create_test_room().await;

    // 准备测试数据
    prepare_stats_data(room.id).await;

    // 查询小时报表
    let query = StatsReportQuery {
        room_ids: Some(vec![room.id]),
        start_time: Utc::now() - Duration::hours(24),
        end_time: Utc::now(),
        granularity: TimeGranularity::Hour,
        metrics: vec![StatsMetric::OnlineCount, StatsMetric::UniqueUsers],
    };

    let response = app
        .get("/admin/api/stats/reports")
        .query(&query)
        .bearer_auth(admin.token)
        .send()
        .await
        .unwrap();

    assert_eq!(response.status(), 200);

    let report: StatsReportResponse = response.json().await.unwrap();
    assert!(!report.stats.is_empty());
    assert!(report.stats[0].peak_online_count > 0);
}

#[tokio::test]
async fn test_admin_permission_required() {
    let app = setup_app().await;
    let regular_user = create_regular_user().await;

    let response = app
        .get("/admin/api/stats/reports")
        .bearer_auth(regular_user.token)
        .send()
        .await
        .unwrap();

    assert_eq!(response.status(), 403); // 禁止访问
}
```

### 数据生命周期测试

```rust
#[tokio::test]
async fn test_data_retention() {
    let db = setup_test_db().await;

    // 插入31天前的事件
    insert_old_events(Utc::now() - Duration::days(31)).await;

    // 运行清理任务
    cleanup_expired_events(&db, Duration::days(30)).await.unwrap();

    // 验证旧数据已删除
    let old_events = query_events_before(Utc::now() - Duration::days(30)).await.unwrap();
    assert_eq!(old_events.len(), 0);
}
```

### 高并发测试

```rust
#[tokio::test]
async fn test_high_concurrency_stats() {
    let presence = setup_redis_presence().await;
    let collector = setup_event_collector().await;
    let room_id = RoomId::new();

    // 并发添加100个用户
    let tasks: Vec<_> = (0..100)
        .map(|i| {
            let presence = presence.clone();
            let collector = collector.clone();
            tokio::spawn(async move {
                let user_id = UserId::from_u64(i);
                let session_id = Uuid::new_v4();
                presence.user_connected_with_full_tracking(
                    room_id,
                    user_id,
                    session_id,
                    &broadcaster,
                    &collector
                ).await
            })
        })
        .collect();

    let results: Vec<_> = futures::future::join_all(tasks).await;

    // 所有操作都应该成功
    assert!(results.iter().all(|r| r.is_ok()));

    // 最终实时统计应该正确
    assert_eq!(presence.get_online_count(room_id).await.unwrap(), 100);

    // 历史数据也应该正确记录
    tokio::time::sleep(Duration::from_secs(2)).await;
    let events = query_events_count(room_id).await.unwrap();
    assert_eq!(events, 100);
}
```

## 4. 验收标准

### 实时统计层

- **准确性**：在线统计数量始终与实际在线用户一致
- **实时性**：用户状态变化后1秒内推送统计更新
- **性能**：统计查询响应时间 < 5ms（缓存命中）
- **可靠性**：Redis故障时能降级到数据库查询
- **并发性**：支持1000并发用户状态变化不出错

### 历史报表层

- **数据完整性**：所有用户状态变化事件100%记录
- **聚合准确性**：聚合数据与原始事件计算结果一致
- **查询性能**：
  - 小时粒度查询 < 100ms
  - 日粒度查询 < 500ms
  - 月粒度查询 < 2s
  - 年粒度查询 < 5s
- **数据一致性**：实时统计与历史数据的最终一致性
- **存储效率**：
  - 原始事件压缩率 > 50%
  - 聚合数据占用 < 原始数据的10%

### 管理员功能

- **权限控制**：仅管理员可访问历史报表API
- **审计日志**：所有管理员查询操作记录审计日志
- **报表多样性**：支持小时/日/周/月/年多个时间粒度
- **数据可视化**：返回格式便于前端图表渲染
- **导出功能**：支持CSV/Excel格式导出

### 系统稳定性

- **异步写入**：事件采集不阻塞实时功能，延迟 < 10ms
- **批量优化**：批量插入性能 > 单条插入10倍
- **故障恢复**：数据库故障时事件队列缓冲，恢复后补写
- **内存控制**：事件队列最大缓冲10000条，超出则丢弃最旧事件
- **分区管理**：自动创建新分区，自动清理过期分区

### 兼容性要求

- **向后兼容**：不破坏现有WebSocket协议和实时统计API
- **平滑升级**：可以无停机部署历史统计功能
- **数据迁移**：现有系统升级后自动开始采集，无需历史数据

## 5. 抉择原因

### 技术层面

#### 数据结构优势

- **双层架构清晰**：实时层和历史层职责分离，互不干扰
- **Redis Sets实时性**：O(1)计数，满足低延迟要求
- **PostgreSQL时序存储**：分区表优化，支持海量历史数据
- **聚合策略合理**：定时聚合降低实时计算压力

#### 架构一致性

- **基于现有组件扩展**：PresenceManager扩展，不引入新抽象
- **异步解耦设计**：事件采集异步化，不影响实时性能
- **分层存储策略**：原始事件短期，聚合数据长期，经济高效

#### 性能考虑

- **批量写入优化**：批量插入提升10倍性能
- **分区表加速查询**：时间分区使范围查询性能稳定
- **多级聚合加速**：小时/日/月/年预聚合，避免实时计算
- **索引优化**：精心设计的复合索引支持多维度查询

### 业务层面

#### 用户体验

- **实时反馈**：用户看到房间活跃度，增强参与感
- **无感知采集**：历史数据采集完全透明，不影响用户体验

#### 运营价值

- **趋势分析**：了解用户活跃时段，优化运营策略
- **容量规划**：基于历史峰值数据预测资源需求
- **效果评估**：功能上线前后对比，量化产品效果
- **异常监控**：实时和历史数据双重验证，快速发现问题

#### 产品决策

- **数据驱动**：用真实数据替代拍脑袋决策
- **A/B测试**：为实验效果评估提供量化依据
- **用户画像**：分析用户行为模式，优化产品设计
- **商业价值**：为商业化提供数据支撑

### Linus式思维验证

#### 好品味原则

- **消除特殊情况**：管理员不再"盲飞运营"，有据可依
- **数据结构优先**：时序数据是核心，实时只是快照
- **简洁而完整**：双层架构清晰，各司其职

#### 简洁性原则

- **最小复杂度**：只扩展必要组件，不引入过度抽象
- **代码增量可控**：基于现有基础设施，增量开发
- **维护成本合理**：分层存储和自动化清理降低运维成本

#### 向后兼容原则

- **零破坏性**：完全不影响现有实时统计功能
- **渐进式部署**：可以先部署采集，后开放报表
- **数据独立性**：历史数据系统独立，可随时关闭

#### 实用主义原则

- **解决真实需求**：运营确实需要历史数据做决策
- **性能与成本平衡**：异步采集不影响实时性，聚合降低查询成本
- **可维护性优先**：自动化分区管理和数据清理，减少人工介入

## 实施路径

### 第一阶段：实时统计（1-2周）

1. 扩展PresenceManager trait
2. 实现Redis统计查询和缓存
3. 添加WebSocket实时推送

### 第二阶段：数据采集（2-3周）

4. 实现异步事件采集器
5. 设计PostgreSQL时序表结构
6. 部署数据采集但不开放查询

### 第三阶段：数据聚合（2-3周）

7. 实现小时/日/月/年聚合任务
8. 优化SQL聚合查询性能
9. 实现数据生命周期管理

### 第四阶段：报表查询（1-2周）

10. 实现管理员报表API
11. 添加权限验证和审计日志
12. 性能测试和优化

### 第五阶段：完善优化（持续）

13. 监控告警系统
14. 数据可视化支持
15. 导出功能和高级查询

**核心思想：双层架构，实时与历史分离。基于现有Redis基础设施扩展实时统计，基于PostgreSQL时序存储支持历史报表。用最少的复杂度，实现最大的业务价值。**
